{
  "name": "MMRAG Chat Brain (Webhook)",
  "nodes": [
    {
      "parameters": { "path": "rag-chat", "httpMethod": "POST", "responseMode": "lastNode" },
      "id": "Webhook_Chat",
      "name": "Webhook (rag-chat)",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [200, 200],
      "webhookId": "69e2e6f5-fa2e-4d14-a206-950e172f6931"
    },
    {
      "parameters": {
        "mode": "runOnceForAllItems",
        "language": "javaScript",
        "jsCode": "const body = $json.body || $json;\nconst msgs = body.messages || [];\nlet q = body.query;\n\nif (!q && msgs.length) {\n  for (let i = msgs.length - 1; i >= 0; i--) {\n    if (msgs[i].role === 'user') { q = msgs[i].content; break; }\n  }\n}\nq = q || '';\n\n// Follow-up query rewriting: detect short follow-ups with conversation history\nconst lastAssistant = msgs.filter(m => m.role === 'assistant').slice(-1)[0];\nif (lastAssistant && q.length < 100) {\n  let hint = lastAssistant.content;\n  const preamblePatterns = /^(Basierend auf|Laut den Dokumenten|Gemäß|Auf Grundlage|Den Dokumenten zufolge)/i;\n  if (preamblePatterns.test(hint)) {\n    const firstSentEnd = hint.search(/[.!?:]\\s/);\n    if (firstSentEnd > 0 && firstSentEnd < 150) {\n      hint = hint.substring(firstSentEnd + 2);\n    }\n  }\n  hint = hint.substring(0, 150).trim();\n  q = q + ' ' + hint;\n}\n\n// Document filter: parse optional @filename prefix\nlet docFilter = '';\nlet hasDocFilter = false;\nif (q.startsWith('@')) {\n  const spaceIdx = q.indexOf(' ');\n  if (spaceIdx > 0) {\n    docFilter = q.substring(1, spaceIdx);\n    docFilter = docFilter.replace(/[^\\w.\\-]/g, '_');\n    hasDocFilter = true;\n    q = q.substring(spaceIdx + 1).trim();\n  }\n}\n\nreturn [{ json: {\n  query: q,\n  originalQuery: body.query || q,\n  docFilter,\n  hasDocFilter,\n  embedRequestBody: { model: $env.OLLAMA_EMBED_MODEL || 'nomic-embed-text', prompt: q }\n} }];"
      },
      "id": "Fn_ExtractQuery",
      "name": "Extract Query",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [420, 200]
    },
    {
      "parameters": {
        "url": "http://ollama:11434/api/embeddings",
        "method": "POST",
        "sendBody": true,
        "contentType": "json",
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json.embedRequestBody) }}",
        "options": { "timeout": 120000 }
      },
      "id": "HTTP_Embed",
      "name": "Embed Query (Ollama)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [660, 200]
    },
    {
      "parameters": {
        "mode": "runOnceForAllItems",
        "language": "javaScript",
        "jsCode": "const emb = $json.embedding || [];\nconst embVec = '[' + emb.join(',') + ']';\nconst eq = $('Extract Query').first().json;\nreturn [{ json: { query: eq.query, docFilter: eq.docFilter, hasDocFilter: eq.hasDocFilter, embedding_vec: embVec } }];"
      },
      "id": "Fn_VectorLiteral",
      "name": "To Vector Literal",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [900, 200]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "=SELECT chunk_type, page, content_text, caption, asset_path,\n       1 - (embedding <=> '{{$json.embedding_vec}}'::vector) AS score\nFROM rag_chunks\nWHERE embedding IS NOT NULL\n  AND embedding <=> '{{$json.embedding_vec}}'::vector < {{ $env.VECTOR_DISTANCE_THRESHOLD || '0.5' }}\n  AND (\n    {{$json.hasDocFilter}} = false\n    OR doc_id IN (\n      SELECT doc_id FROM rag_docs\n      WHERE filename ILIKE '%' || '{{$json.docFilter}}' || '%'\n    )\n  )\nORDER BY embedding <=> '{{$json.embedding_vec}}'::vector\nLIMIT 6;"
      },
      "id": "PG_VectorSearch",
      "name": "Vector Search (Postgres)",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2,
      "position": [1140, 200]
    },
    {
      "parameters": {
        "mode": "runOnceForAllItems",
        "language": "javaScript",
        "jsCode": "const hits = ($('Vector Search (Postgres)').all() || []).map(it => it.json);\nconst base = $env.PUBLIC_ASSETS_BASE_URL || '';\nconst images = hits\n  .filter(h => h.chunk_type === 'image' && h.asset_path)\n  .map(h => `${base}/${h.asset_path}`);\nconst ctxLines = hits.map(h => {\n  if (h.chunk_type === 'image') {\n    const url = h.asset_path ? `${base}/${h.asset_path}` : '';\n    return `Bild (Seite ${h.page}): ${h.caption || ''} ${url}`.trim();\n  }\n  return `Text (Seite ${h.page}): ${h.content_text || ''}`;\n});\nconst sources = hits.map(h => `Seite ${h.page} (${h.chunk_type})`).slice(0, 8);\nconst query = $('Extract Query').first().json.query;\nconst context = ctxLines.join('\\n\\n');\nconst chatRequestBody = {\n  model: $env.OLLAMA_TEXT_MODEL || 'llama3.1:8b',\n  stream: false,\n  options: { num_predict: 400 },\n  messages: [\n    {role: 'system', content: 'Du bist ein präziser Assistent. Antworte auf Deutsch. Zitiere Seitenzahlen wenn möglich.'},\n    {role: 'user', content: 'Frage: ' + query + '\\n\\nKontext aus Dokumenten:\\n' + context + '\\n\\nAntworte kurz, korrekt und mit Seitenhinweisen.'}\n  ]\n};\nreturn [{ json: { query, context, images, sources, chatRequestBody } }];"
      },
      "id": "Fn_BuildContext",
      "name": "Build Context",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1380, 200]
    },
    {
      "parameters": {
        "url": "http://ollama:11434/api/chat",
        "method": "POST",
        "sendBody": true,
        "contentType": "json",
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json.chatRequestBody) }}",
        "options": { "timeout": 180000 }
      },
      "id": "HTTP_Generate",
      "name": "Generate Answer (Ollama)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [1620, 200]
    },
    {
      "parameters": {
        "mode": "runOnceForAllItems",
        "language": "javaScript",
        "jsCode": "const msg = $json.message?.content || '';\nconst ctx = $('Build Context').first().json;\nreturn [{ json: { answer: msg, images: ctx.images || [], sources: ctx.sources || [] } }];"
      },
      "id": "Fn_FormatResponse",
      "name": "Format Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1860, 200]
    }
  ],
  "connections": {
    "Webhook (rag-chat)": { "main": [[{ "node": "Extract Query", "type": "main", "index": 0 }]] },
    "Extract Query": { "main": [[{ "node": "Embed Query (Ollama)", "type": "main", "index": 0 }]] },
    "Embed Query (Ollama)": { "main": [[{ "node": "To Vector Literal", "type": "main", "index": 0 }]] },
    "To Vector Literal": { "main": [[{ "node": "Vector Search (Postgres)", "type": "main", "index": 0 }]] },
    "Vector Search (Postgres)": { "main": [[{ "node": "Build Context", "type": "main", "index": 0 }]] },
    "Build Context": { "main": [[{ "node": "Generate Answer (Ollama)", "type": "main", "index": 0 }]] },
    "Generate Answer (Ollama)": { "main": [[{ "node": "Format Response", "type": "main", "index": 0 }]] }
  },
  "active": false,
  "settings": {},
  "versionId": "frozen-v2.4"
}
